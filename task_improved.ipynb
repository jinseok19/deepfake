{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c65c32d",
   "metadata": {},
   "source": [
    "## 딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회\n",
    "\n",
    "**※주의** : 반드시 본 파일을 이용하여 제출을 수행해야 하며, 파일의 이름은 `task.ipynb`로 유지되어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a9781",
   "metadata": {},
   "source": [
    "* #### 추론 실행 환경\n",
    "    * `python 3.9` 환경\n",
    "    * `CUDA 10.2`, `CUDA 11.8`, `CUDA 12.6`를 지원합니다.\n",
    "    * 각 CUDA 환경에 미리 설치돼있는 torch 버전은 다음 표를 참고하세요.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">Python</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "      <th align=\"center\">torch</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.8</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "      <td align=\"center\">1.6.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.9</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "      <td align=\"center\">1.8.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">3.10</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "      <td align=\"center\">2.7.1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001744a",
   "metadata": {},
   "source": [
    "* #### CUDA 버전 관련 안내사항  \n",
    "  - 이번 경진대회는 3개의 CUDA 버전을 지원합니다.  \n",
    "  - 참가자는 자신의 모델의 라이브러리 의존성에 맞는 CUDA 환경을 선택하여 모델을 제출하면 됩니다.   \n",
    "  - 각 CUDA 환경에는 기본적으로 torch가 설치되어 있으나, 참가자는 제출하는 CUDA 버전과 호환되는 torch, 필요한 버전의 라이브러리를 `!pip install` 하여 사용하여도 무관합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b530b5",
   "metadata": {},
   "source": [
    "* #### `task.ipynb` 작성 규칙\n",
    "코드는 크게 3가지 파트로 구성되며, 해당 파트의 특성을 지켜서 내용을 편집하세요.   \n",
    "1. **제출용 aifactory 라이브러리 및 추가 필요 라이브러리 설치**\n",
    "    - 채점 및 제출을 위한 aifactory 라이브러리를 설치하는 셀입니다. 이 부분은 수정하지 않고 그대로 실행합니다.\n",
    "    - 그 외로, 모델 추론에 필요한 라이브러리를 직접 설치합니다.\n",
    "2. **추론용 코드 작성**\n",
    "    - 모델 로드, 데이터 전처리, 예측 등 실제 추론을 수행하는 모든 코드를 이 영역에 작성합니다.\n",
    "3. **aif.submit() 함수를 호출하여 최종 결과를 제출**\n",
    "    - **마이 페이지-활동히스토리**에서 발급받은 key 값을 함수의 인자로 정확히 입력해야 합니다.\n",
    "    - **※주의** : 제출하고자 하는 CUDA 환경에 맞는 key를 입력하여야 합니다.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"left\">Competition 이름</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회 CUDA 12.6</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회 CUDA 10.2</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e0843",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e2061",
   "metadata": {},
   "source": [
    "#### 1. 제출용 aifactory 라이브러리 설치\n",
    "※ 결과 전송에 필요하므로 아래와 같이 aifactory 라이브러리가 반드시 최신버전으로 설치될 수 있게끔 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acd91eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aifactory\n",
      "  Downloading aifactory-2.0.0-py3-none-any.whl.metadata (317 bytes)\n",
      "Collecting pipreqs (from aifactory)\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting ipynbname (from aifactory)\n",
      "  Downloading ipynbname-2025.8.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gdown (from aifactory)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aifactory) (2.32.5)\n",
      "Requirement already satisfied: IPython in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aifactory) (8.18.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from gdown->aifactory) (4.14.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from gdown->aifactory) (3.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from gdown->aifactory) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from beautifulsoup4->gdown->aifactory) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from beautifulsoup4->gdown->aifactory) (4.15.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipynbname->aifactory) (6.31.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (7.1.2)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (2.19.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from IPython->aifactory) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->aifactory) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jedi>=0.16->IPython->aifactory) (0.8.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (8.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (3.23.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->ipynbname->aifactory) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->ipynbname->aifactory) (311)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (1.17.0)\n",
      "Collecting docopt==0.6.2 (from pipreqs->aifactory)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting IPython (from aifactory)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nbconvert<8.0.0,>=7.11.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from pipreqs->aifactory) (7.16.6)\n",
      "Collecting yarg==0.1.9 (from pipreqs->aifactory)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting backcall (from IPython->aifactory)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pickleshare (from IPython->aifactory)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.6)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (4.25.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->aifactory) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->aifactory) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->aifactory) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->aifactory) (2025.10.5)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown->aifactory)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (0.2.3)\n",
      "Downloading aifactory-2.0.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading ipynbname-2025.8.0.0-py3-none-any.whl (4.5 kB)\n",
      "Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 798.3/798.3 kB 3.8 MB/s  0:00:00\n",
      "Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (pyproject.toml): started\n",
      "  Building wheel for docopt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13858 sha256=48a1705579709328632f3bdf8a46603b7ffbae2aae4d7d78ff8fa5c7f119798a\n",
      "  Stored in directory: c:\\users\\202210829\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "Installing collected packages: pickleshare, docopt, backcall, PySocks, yarg, IPython, gdown, ipynbname, pipreqs, aifactory\n",
      "\n",
      "   -------- -------------------------------  2/10 [backcall]\n",
      "   ------------ ---------------------------  3/10 [PySocks]\n",
      "   ---------------- -----------------------  4/10 [yarg]\n",
      "  Attempting uninstall: IPython\n",
      "   ---------------- -----------------------  4/10 [yarg]\n",
      "    Found existing installation: ipython 8.18.1\n",
      "   ---------------- -----------------------  4/10 [yarg]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "    Uninstalling ipython-8.18.1:\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "      Successfully uninstalled ipython-8.18.1\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   -------------------- -------------------  5/10 [IPython]\n",
      "   ------------------------ ---------------  6/10 [gdown]\n",
      "   ------------------------ ---------------  6/10 [gdown]\n",
      "   ------------------------ ---------------  6/10 [gdown]\n",
      "   ---------------------------- -----------  7/10 [ipynbname]\n",
      "   -------------------------------- -------  8/10 [pipreqs]\n",
      "   ------------------------------------ ---  9/10 [aifactory]\n",
      "   ------------------------------------ ---  9/10 [aifactory]\n",
      "   ---------------------------------------- 10/10 [aifactory]\n",
      "\n",
      "Successfully installed IPython-8.12.3 PySocks-1.7.1 aifactory-2.0.0 backcall-0.2.0 docopt-0.6.2 gdown-5.2.0 ipynbname-2025.8.0.0 pickleshare-0.7.5 pipreqs-0.5.0 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -U aifactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0deb93f",
   "metadata": {},
   "source": [
    "* 자신의 모델 추론 실행에 필요한 추가 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6ceb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.30 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (4.30.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (2.32.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from transformers==4.30) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.30) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->transformers==4.30) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->transformers==4.30) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->transformers==4.30) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests->transformers==4.30) (2025.10.5)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.22.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torch==2.7.1) (2025.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torchvision==0.22.1) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from torchvision==0.22.1) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from jinja2->torch==2.7.1) (2.1.5)\n",
      "Requirement already satisfied: datasets in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: opencv-python==4.10.0.82 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy==1.11.4 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from scikit-learn==1.3.2) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (from scikit-learn==1.3.2) (3.6.0)\n",
      "Requirement already satisfied: pathlib in c:\\users\\202210829\\documents\\github\\deepfake\\venv\\lib\\site-packages (1.0.1)\n",
      "Collecting dlib"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for dlib (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [41 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      \n",
      "                         CMake is not installed on your system!\n",
      "      \n",
      "          Or it is possible some broken copy of cmake is installed on your system.\n",
      "          It is unfortunately very common for python package managers to include\n",
      "          broken copies of cmake.  So if the error above this refers to some file\n",
      "          path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "          should delete that broken copy of cmake from your computer.\n",
      "      \n",
      "          Instead, please get an official copy of cmake from one of these known good\n",
      "          sources of an official cmake:\n",
      "              - cmake.org (this is how windows users should get cmake)\n",
      "              - apt install cmake (for Ubuntu or Debian based systems)\n",
      "              - yum install cmake (for Redhat or CenOS based systems)\n",
      "      \n",
      "          On a linux machine you can run `which cmake` to see what cmake you are\n",
      "          actually using.  If it tells you it's some cmake from any kind of python\n",
      "          packager delete it and install an official cmake.\n",
      "      \n",
      "          More generally, cmake is not installed if when you open a terminal window\n",
      "          and type\n",
      "             cmake --version\n",
      "          you get an error.  So you can use that as a very basic test to see if you\n",
      "          have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "          same terminal window from which you are reading this error message, then\n",
      "          you have not installed cmake.  Windows users should take note that they\n",
      "          need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "          can't run commands that are not in your PATH.  This is how the PATH works\n",
      "          on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "          common problem on windows and rarely a problem on Linux.\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> dlib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading dlib-20.0.0.tar.gz (3.3 MB)\n",
      "     ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 3.3/3.3 MB 19.4 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (pyproject.toml): started\n",
      "  Building wheel for dlib (pyproject.toml): finished with status 'error'\n",
      "Failed to build dlib\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.30\n",
    "!pip install -U torch==2.7.1 torchvision==0.22.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -U datasets\n",
    "!pip install -U opencv-python==4.10.0.82 numpy==1.26.4 scikit-learn==1.3.2 scipy==1.11.4\n",
    "!pip install -U pathlib\n",
    "!pip install -U dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19999e24",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1b43e",
   "metadata": {},
   "source": [
    "#### 2. 추론용 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d194e",
   "metadata": {},
   "source": [
    "##### 추론 환경의 기본 경로 구조\n",
    "\n",
    "- 평가 데이터셋 경로: `./data/`\n",
    "   - 채점에 사용될 테스트 데이터셋은 `./data/` 디렉토리 안에 포함되어 있습니다.\n",
    "   - 해당 디렉토리에는 이미지(JPG, PNG)와 동영상(MP4) 파일이 별도의 하위 폴더 없이 혼합되어 있습니다.\n",
    "```bash\n",
    "/aif/\n",
    "└── data/\n",
    "    ├── {이미지 데이터1}.jpg\n",
    "    ├── {이미지 데이터2}.png\n",
    "    ├── {동영상 데이터1}.mp4\n",
    "    ├── {이미지 데이터3}.png\n",
    "    ├── {동영상 데이터2}.mp4\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335719c1",
   "metadata": {},
   "source": [
    "- 모델 및 자원 경로: 예시 : `./model/`\n",
    "   - 추론 스크립트가 실행되는 위치를 기준으로, 제출된 모델 관련 파일들이 위치해야하 하는 상대 경로입니다.\n",
    "   - 학습된 모델 가중치(.pt, .ckpt, .pth 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1810d",
   "metadata": {},
   "source": [
    "* 제출 파일은 `submission.csv`로 저장돼야 합니다.\n",
    "  * submission.csv는 *filename*과 *label* 컬럼으로 구성돼야 합니다.\n",
    "  * filename은 추론한 파일의 이름(확장자 포함), label은 추론 결과입니다. (real:0, fake:1)\n",
    "  * filename은 *string*, label은 *int* 자료형이어야 합니다.\n",
    "  * 추론하는 데이터의 순서는 무작위로 섞여도 상관 없습니다.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">filename</th>\n",
    "      <th align=\"center\">label</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\">{이미지 데이터1}.jpg</td>\n",
    "      <td align=\"center\">0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">{동영상 데이터1}.mp4</td>\n",
    "      <td align=\"center\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td colspan=\"2\" align=\"center\">...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29c10f",
   "metadata": {},
   "source": [
    "**※ 주의 사항**\n",
    "\n",
    "* argparse 사용시 `args, _ = parser.parse_known_args()`로 인자를 지정하세요.   \n",
    "   - `args = parser.parse_args()`는 jupyter에서 오류가 발생합니다.\n",
    "* return 할 결과물과 양식에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff1c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "딥페이크 탐지 모델 - Improved Version\n",
      "==================================================\n",
      "Device: cuda\n",
      "\n",
      "[1/4] 모델 로딩...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of './model/deep-fake-detector-v2-model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './model/deep-fake-detector-v2-model' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:629\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/deep-fake-detector-v2-model'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 192\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# 모델 로드\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[1/4] 모델 로딩...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 192\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mViTForImageClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    193\u001b[0m processor \u001b[38;5;241m=\u001b[39m ViTImageProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m    194\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:2305\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   2304\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[1;32m-> 2305\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   2306\u001b[0m         config_path,\n\u001b[0;32m   2307\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2308\u001b[0m         return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2309\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   2310\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m   2311\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   2312\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2313\u001b[0m         use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token,\n\u001b[0;32m   2314\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2315\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m   2316\u001b[0m         _from_auto\u001b[38;5;241m=\u001b[39mfrom_auto_class,\n\u001b[0;32m   2317\u001b[0m         _from_pipeline\u001b[38;5;241m=\u001b[39mfrom_pipeline,\n\u001b[0;32m   2318\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2319\u001b[0m     )\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2321\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:547\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    471\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m     config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    549\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    550\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:574\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 574\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    576\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\202210829\\Documents\\GITHUB\\deepfake\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:650\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the configuration of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    653\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    654\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    655\u001b[0m         )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load the configuration of './model/deep-fake-detector-v2-model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './model/deep-fake-detector-v2-model' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "## 필요 라이브러리 import\n",
    "import os\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import dlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "### 추론 환경 경로 설정\n",
    "model_path = \"./model/deep-fake-detector-v2-model\"\n",
    "test_dataset_path = Path(\"./data\")\n",
    "output_csv_path = Path(\"submission.csv\")\n",
    "\n",
    "# 상수\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "VIDEO_EXTS = {\".avi\", \".mp4\"}\n",
    "TARGET_SIZE = (224, 224)\n",
    "NUM_FRAMES = 30\n",
    "BATCH_SIZE = 16  # GPU 배치 처리\n",
    "\n",
    "# 집계 가중치 (mean vs max)\n",
    "MEAN_WEIGHT = 0.6\n",
    "MAX_WEIGHT = 0.4\n",
    "\n",
    "\n",
    "def get_boundingbox(face, width, height, margin=1.3):\n",
    "    \"\"\"얼굴 바운딩 박스 추출 (여유 공간 포함)\"\"\"\n",
    "    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "    size_bb = int(max(x2 - x1, y2 - y1) * margin)\n",
    "    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "    x1 = max(int(center_x - size_bb // 2), 0)\n",
    "    y1 = max(int(center_y - size_bb // 2), 0)\n",
    "    size_bb = min(width - x1, size_bb)\n",
    "    size_bb = min(height - y1, size_bb)\n",
    "    return x1, y1, size_bb\n",
    "\n",
    "\n",
    "def center_crop_image(image: Image.Image, target_size=(224, 224)):\n",
    "    \"\"\"얼굴 미검출 시 중앙 크롭 사용\"\"\"\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    width, height = image.size\n",
    "    crop_size = min(width, height)\n",
    "    left = (width - crop_size) // 2\n",
    "    top = (height - crop_size) // 2\n",
    "    right = left + crop_size\n",
    "    bottom = top + crop_size\n",
    "    \n",
    "    cropped = image.crop((left, top, right, bottom))\n",
    "    return cropped.resize(target_size, Image.BICUBIC)\n",
    "\n",
    "\n",
    "def detect_and_crop_face(image: Image.Image, target_size=(224, 224), resize_for_detection=640):\n",
    "    \"\"\"얼굴 검출 및 크롭 (개선: 미검출 시 중앙 크롭)\"\"\"\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    original_np = np.array(image)\n",
    "    original_h, original_w, _ = original_np.shape\n",
    "    \n",
    "    # 얼굴 검출용 리사이즈\n",
    "    if original_w > resize_for_detection:\n",
    "        scale = resize_for_detection / float(original_w)\n",
    "        resized_h = int(original_h * scale)\n",
    "        resized_np = cv2.resize(original_np, (resize_for_detection, resized_h), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "        resized_np = original_np\n",
    "    \n",
    "    # dlib 얼굴 검출\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    faces = face_detector(resized_np, 1)\n",
    "    \n",
    "    # 얼굴 검출 실패 시 중앙 크롭 사용\n",
    "    if not faces:\n",
    "        return center_crop_image(image, target_size), False  # False = 얼굴 미검출\n",
    "    \n",
    "    # 가장 큰 얼굴 선택\n",
    "    face = max(faces, key=lambda rect: rect.width() * rect.height())\n",
    "    \n",
    "    # 원본 이미지 좌표로 변환\n",
    "    scaled_face_rect = dlib.rectangle(\n",
    "        left=int(face.left() / scale),\n",
    "        top=int(face.top() / scale),\n",
    "        right=int(face.right() / scale),\n",
    "        bottom=int(face.bottom() / scale)\n",
    "    )\n",
    "    \n",
    "    x, y, size = get_boundingbox(scaled_face_rect, original_w, original_h)\n",
    "    cropped_np = original_np[y:y + size, x:x + size]\n",
    "    face_img = Image.fromarray(cropped_np).resize(target_size, Image.BICUBIC)\n",
    "    \n",
    "    return face_img, True  # True = 얼굴 검출 성공\n",
    "\n",
    "\n",
    "def process_single_file(file_path):\n",
    "    \"\"\"파일 하나 전처리 (병렬 처리용)\"\"\"\n",
    "    face_images = []\n",
    "    face_detected_flags = []\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    try:\n",
    "        if ext in IMAGE_EXTS:\n",
    "            image = Image.open(file_path)\n",
    "            face_img, detected = detect_and_crop_face(image, TARGET_SIZE)\n",
    "            face_images.append(face_img)\n",
    "            face_detected_flags.append(detected)\n",
    "            \n",
    "        elif ext in VIDEO_EXTS:\n",
    "            cap = cv2.VideoCapture(str(file_path))\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "            if total_frames > 0:\n",
    "                frame_indices = np.linspace(0, total_frames - 1, NUM_FRAMES, dtype=int)\n",
    "                for idx in frame_indices:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        continue\n",
    "                    \n",
    "                    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                    face_img, detected = detect_and_crop_face(image, TARGET_SIZE)\n",
    "                    face_images.append(face_img)\n",
    "                    face_detected_flags.append(detected)\n",
    "            \n",
    "            cap.release()\n",
    "            \n",
    "    except Exception as e:\n",
    "        return file_path.name, [], [], str(e)\n",
    "    \n",
    "    return file_path.name, face_images, face_detected_flags, None\n",
    "\n",
    "\n",
    "def predict_batch(model, processor, images, device=\"cuda\"):\n",
    "    \"\"\"배치 단위 GPU 추론\"\"\"\n",
    "    if not images:\n",
    "        return []\n",
    "    \n",
    "    inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)  # [N, 2]\n",
    "    \n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "\n",
    "def aggregate_video_predictions(probs_list, face_detected_flags):\n",
    "    \"\"\"\n",
    "    동영상 프레임 확률 집계 (개선)\n",
    "    - mean + max 확률 조합\n",
    "    - 얼굴 검출 실패 프레임 가중치 낮춤\n",
    "    \"\"\"\n",
    "    if not probs_list:\n",
    "        return 0  # 기본값 Real\n",
    "    \n",
    "    probs_array = np.array(probs_list)  # [N, 2]\n",
    "    \n",
    "    # 얼굴 검출 성공 프레임만 사용 (최소 1개는 사용)\n",
    "    detected_indices = [i for i, flag in enumerate(face_detected_flags) if flag]\n",
    "    if detected_indices:\n",
    "        probs_array = probs_array[detected_indices]\n",
    "    \n",
    "    # Mean과 Max 확률 조합\n",
    "    mean_probs = probs_array.mean(axis=0)\n",
    "    max_probs = probs_array.max(axis=0)\n",
    "    \n",
    "    combined_probs = MEAN_WEIGHT * mean_probs + MAX_WEIGHT * max_probs\n",
    "    \n",
    "    return np.argmax(combined_probs)\n",
    "\n",
    "\n",
    "# --- 메인 추론 로직 ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"딥페이크 탐지 모델 - Improved Version\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    print(\"\\n[1/4] 모델 로딩...\")\n",
    "    model = ViTForImageClassification.from_pretrained(model_path).to(device)\n",
    "    processor = ViTImageProcessor.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    print(\"✓ 모델 로드 완료\")\n",
    "    \n",
    "    # 파일 리스트\n",
    "    files = sorted([p for p in test_dataset_path.iterdir() if p.is_file()])\n",
    "    print(f\"\\n[2/4] 테스트 데이터: {len(files)}개 파일\")\n",
    "    \n",
    "    # CPU 워커 설정\n",
    "    num_workers = min(max(1, multiprocessing.cpu_count() - 1), 8)\n",
    "    print(f\"\\n[3/4] 전처리 시작 (workers: {num_workers})\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 병렬 전처리 + 순차 추론\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        with tqdm(total=len(files), desc=\"Processing\") as pbar:\n",
    "            for filename, face_images, face_flags, error in pool.imap_unordered(process_single_file, files):\n",
    "                if error:\n",
    "                    print(f\"\\n⚠ Error: {filename} - {error}\")\n",
    "                    results[filename] = 0\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                if not face_images:\n",
    "                    results[filename] = 0\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # 배치 단위로 GPU 추론\n",
    "                all_probs = []\n",
    "                for i in range(0, len(face_images), BATCH_SIZE):\n",
    "                    batch = face_images[i:i + BATCH_SIZE]\n",
    "                    batch_probs = predict_batch(model, processor, batch, device)\n",
    "                    all_probs.extend(batch_probs)\n",
    "                \n",
    "                # 이미지: 단일 예측, 동영상: 집계\n",
    "                if len(all_probs) == 1:\n",
    "                    predicted_class = np.argmax(all_probs[0])\n",
    "                else:\n",
    "                    predicted_class = aggregate_video_predictions(all_probs, face_flags)\n",
    "                \n",
    "                results[filename] = predicted_class\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # CSV 저장\n",
    "    print(\"\\n[4/4] 결과 저장 중...\")\n",
    "    with open(output_csv_path, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"label\"])\n",
    "        for p in files:\n",
    "            filename = p.name\n",
    "            label = results.get(filename, 0)\n",
    "            writer.writerow([filename, label])\n",
    "    \n",
    "    print(f\"\\n✓ 추론 완료! 결과 저장: {output_csv_path}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119d40d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f895e41",
   "metadata": {},
   "source": [
    "#### 3. `aif.submit()` 함수를 호출하여 최종 결과를 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410d97e",
   "metadata": {},
   "source": [
    "**※주의** : task별, 참가자별로 key가 다릅니다. 잘못 입력하지 않도록 유의바랍니다.\n",
    "- key는 대회 페이지 [베이스라인 코드](https://aifactory.space/task/9197/baseline) 탭에 기재된 가이드라인을 따라 task 별로 확인하실 수 있습니다.\n",
    "- key가 틀리면 제출이 진행되지 않거나 잘못 제출되므로 task에 맞는 자신의 key를 사용해야 합니다.\n",
    "-  **NOTE** : 이번 경진대회에서는 3개의 CUDA 버전을 지원하며, 각 CUDA 버전에 따라 task key가 상이합니다. 함수를 실행하기 전에 현재 key가 제출하고자 하는 CUDA 환경에 대한 key인지 반드시 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4df34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task\n",
      "jupyter notebook\n",
      "제출 완료\n",
      "35.576070070266724\n"
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "aif.submit(model_name=\"your_model_name\",\n",
    "    key=\"your_key\"\n",
    ")\n",
    "#-----------------------------------------------------#\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ac2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
