# 딥페이크 데이터셋 생성 세미나 요약

- 영상: [딥페이크 탐지모델 경진대회 데이터셋 생성관련 세미나](https://www.youtube.com/watch?v=xHvVRlA5JbQ)

## 5–10개 요약(타임스탬프 포함)
- 01:34 세미나 취지: 최신 딥페이크 생성기에 대응하기 위한 “직접 데이터셋 생성” 방법 안내
- 03:28 필요성: 공개 세트가 구형 분포 → 최신 생성기 대응/성능 상향 위해 자체 생성·검증 필수
- 04:54 모델 선정: 리더보드(주제별 people/portrait)로 생성모델 비교, 순위 상위 모델 우선 탐색
- 08:43 상용 플랫폼: Kling AI(이미지→비디오, 립싱크), 기타 플랫폼을 동일 프롬프트로 병렬 생성해 커버리지 확대
- 11:57 프롬프트 워크플로: ChatGPT로 이미지 프롬프트 생성 → 이미지 생성 → 비디오 프롬프트로 확장 → 비디오 생성(12:59)
- 14:42 멀티모델 허브: 한 플랫폼에서 다양한 SOTA 생성모델 구독/교차 사용으로 분포 다양화
- 15:18 평가 입력: 테스트셋은 이미지+동영상(단일 얼굴). 베이스라인도 둘 다 입력 지원, 시간 피처 사용은 선택(26:19 정정)
- 18:59 ComfyUI: 템플릿/갤러리 워크플로로 T2I·I2V·페이스스왑 조합, 오프라인 대량 생성→필터링
- 27:03 범위: 존재하지 않는 가짜 얼굴 생성, 얼굴 스왑/립싱크 모두 딥페이크로 간주
- 32:25 라이선스/개인정보: 학습 가능 라이선스·출처 명확 데이터만 사용, 리얼 데이터는 개인정보 유의. 대회는 학습데이터 미제공(17:10)

## 데이터셋 생성 전략(실무)
- 생성 분포 정합: 유튜브/SNS 업로드 환경을 가정(재인코딩, 해상도/압축변형)으로 현실 분포 맞춤
- 생성기 다양화: 상용(예: Kling AI 등) + 오픈워크플로(ComfyUI, Face Fusion, DeepFaceLab) 혼합
- 프롬프트 표준화: 주제·구도·조명·표정·카메라 파라미터를 템플릿화 → 플랫폼/모델 간 동일 적용
- 얼굴 가시성: “단일 얼굴이 명확히 보이도록” 규격화(대회 입력 제약과 일치)
- 대량 생성→선별: 품질 메트릭(얼굴 검출 성공, 해상도/노이즈, 아티팩트)로 1차 필터, 휴리스틱/수동 QC 병행

## ComfyUI 활용 포인트
- 템플릿 우선: T2I, I2V, Face Swap 템플릿으로 빠른 시작 → 파라미터(CFG, steps, sampler)만 최소 조정
- 워크플로 갤러리: 인기 워크플로를 가져와 스텝 결합(T2I→I2V 파이프라인) 후 배치 실행
- 리소스 관리: VRAM 한도 내 해상도 고정, 시드 고정으로 재현성 확보, 체크포인트/LoRA 버전 기록

## 평가·모델 인터페이스 요건(대회)
- 입력: 이미지(.jpg/.png) + 동영상(.mp4), 단일 얼굴 보장
- 모델: 이미지/동영상을 모두 처리(프레임 기반 가능), 시간 피처는 선택
- 메트릭: Macro F1(Real=0, Fake=1)

## 라이선스/윤리
- “학습 가능” 라이선스·출처 명확 데이터만 사용(개인정보 주의)
- 실존 인물 소재 사용 시 동의·비식별화 고려, 배포 금지 원칙 준수

## 체크리스트(데이터 생성)
- [ ] 주제(people/portrait) 상위 생성기 다수 선정(상용+오픈)
- [ ] 프롬프트 템플릿 정의(얼굴 중심, 단일 인물, 다양한 조명/배경)
- [ ] 이미지→비디오 일관 파이프라인(해상도, fps, 길이 규격)
- [ ] 대량 생성 후 자동 필터링(얼굴 검출 성공, 해상도/압축율, 아티팩트)
- [ ] 리얼틱 변형: 재인코딩, 해상도 다운샘플, 노이즈/압축아티팩트 주입
- [ ] 메타/로그 관리: 생성기/버전/시드/프롬프트 기록

Learn more on Glasp: https://glasp.co/reader?url=https://www.youtube.com/watch?v=xHvVRlA5JbQ
