# EXP-002: 프레임 수 증가 (30→40)

## 📋 실험 정보

| 항목 | 내용 |
|------|------|
| **실험 번호** | EXP-002 |
| **실험 날짜** | 2025-10-29 |
| **베이스 코드** | 베이스라인 (EXP-000) |
| **주요 변경** | NUM_FRAMES: 30 → 40 |
| **F1 Score** | 대기중... |
| **베이스라인 대비** | 대기중... |
| **추론 시간** | 예상 85~90분 |

---

## 🎯 실험 목적

**베이스라인에서 프레임 수만 증가시켜 성능 향상 검증**

- EXP-001에서 여러 변경사항이 오히려 성능 하락 초래
- 가장 안전하고 효과적인 개선 방법부터 단독 테스트
- 더 많은 프레임 = 더 많은 정보 = 더 정확한 판단

---

## 🔧 모델 아키텍처

### 사용 모델
- **백본**: `google/vit-base-patch16-224-in21k`
- **모델**: `deep-fake-detector-v2-model` (베이스라인과 동일)
- **입력 크기**: 224x224
- **출력**: Binary Classification (Real:0, Fake:1)

### 모델 파라미터
```python
model = ViTForImageClassification.from_pretrained(model_path).to("cuda")
processor = ViTImageProcessor.from_pretrained(model_path)
model.eval()
```

---

## 🔄 파이프라인 상세

### 1️⃣ 전처리 (Pre-processing)

#### 얼굴 검출 및 크롭
```python
def detect_and_crop_face_optimized(image, target_size=(224, 224)):
    - dlib face detector 사용
    - margin = 1.3 (베이스라인과 동일)
    - 얼굴 없으면 None 반환
```

#### 프레임 샘플링 ⭐ **변경점**
```python
# 베이스라인
num_frames_to_extract = 30

# EXP-002
num_frames_to_extract = 40  # +33% 증가!
```

**변경 근거**:
- 더 많은 프레임 = 더 풍부한 시간적 정보
- 딥페이크 흔적을 놓칠 확률 감소
- 대부분의 딥페이크 대회에서 효과 검증됨

#### 이미지/비디오 처리
```python
- 이미지: 단일 얼굴 검출
- 비디오: 균등 샘플링 (linspace)
  * 30프레임짜리 → 40프레임 샘플링
  * 시작부터 끝까지 균등 분포
```

#### 전처리 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| `NUM_FRAMES` | 40 | 30 → 40 ⬆️ |
| `margin` | 1.3 | 동일 |
| `target_size` | 224×224 | 동일 |
| `resize_for_detection` | 640 | 동일 |
| `얼굴 미검출 처리` | 레이블 0 | 동일 |

**예상 효과**: +2~4% (더 많은 정보)

---

### 2️⃣ 모델링 (Modeling)

#### 추론 로직
```python
# 배치 단위 GPU 추론 (베이스라인과 동일)
inputs = processor(images=face_images, return_tensors="pt").to("cuda")
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    probs = F.softmax(logits, dim=1)
```

#### 모델 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| 모델 | ViT-Base | 동일 |
| Batch Processing | 사용 | 동일 |
| GPU | CUDA 11.8 | 동일 |

**변경 사항**: 없음 (베이스라인과 동일)

**예상 효과**: 0% (변경 없음)

---

### 3️⃣ 후처리 (Post-processing)

#### 예측 집계 (Aggregation)
```python
# Mean only (베이스라인과 동일)
avg_probs = probs.mean(dim=0)
predicted_class = torch.argmax(avg_probs).item()
```

#### 얼굴 미검출 처리
```python
if not face_images:
    results_to_write[filename] = 0  # Real로 분류 (베이스라인과 동일)
```

#### 후처리 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| 집계 방법 | Mean only | 동일 |
| 프레임 필터링 | 없음 | 동일 |
| 얼굴 미검출 | 레이블 0 | 동일 |

**변경 사항**: 없음 (베이스라인과 동일)

**예상 효과**: 0% (변경 없음)

---

## 🔄 베이스라인 대비 변경 사항

### 변경 요약

| 단계 | 변경 항목 | 베이스라인 | EXP-002 | 영향 |
|------|----------|-----------|---------|------|
| 전처리 | NUM_FRAMES | 30 | 40 | ⬆️ |
| 모델링 | - | - | - | - |
| 후처리 | - | - | - | - |

### 변경점 상세 분석

#### ✅ 유일한 변경: 프레임 수 증가
```python
num_frames_to_extract = 40  # 30 → 40
```

**장점**:
- ✅ 더 많은 시간적 정보 확보
- ✅ 딥페이크 흔적 포착 확률 증가
- ✅ 검증된 개선 방법
- ✅ 리스크 낮음

**단점**:
- ⚠️ 추론 시간 증가 (70분 → 85~90분)
- ⚠️ GPU 메모리 사용량 소폭 증가

#### ✅ 유지된 것들 (EXP-001 실패 교훈)
```python
✓ 얼굴 없으면 레이블 0 (중앙 크롭 NO!)
✓ Mean only (Mean+Max NO!)
✓ 모든 프레임 사용 (필터링 NO!)
✓ margin = 1.3 (유지)
```

---

## 📊 결과

### 정량적 결과

| 메트릭 | 베이스라인 | EXP-002 | 변화 |
|--------|-----------|---------|------|
| **Macro F1** | 0.5489 | 대기중... | 대기중... |
| **정확도 추정** | - | 대기중... | - |
| **추론 시간** | ~70분 | 예상 85~90분 | +15~20분 |

### 정성적 분석

**예상 결과**:
1. **성능 향상 예상**: F1 0.57~0.59 (+4~8%)
2. **안정적 개선**: 단일 변경으로 명확한 기여도
3. **검증된 방법**: 대부분의 비디오 대회에서 효과 확인

---

## 🔍 상세 분석

### 성능 영향 요인 분석

#### 1. 프레임 수 증가의 효과

**가설**:
```
더 많은 프레임 → 더 많은 정보 → 더 정확한 판단
```

**메커니즘**:
- 30프레임: 비디오를 30개 구간으로 샘플링
- 40프레임: 비디오를 40개 구간으로 샘플링 (+33%)
- 더 촘촘한 시간 샘플링 → 딥페이크 흔적 놓칠 확률 ⬇️

**예상 시나리오**:
```
비디오 길이가 300프레임이라면:
- 베이스라인: 10프레임마다 1개 샘플링
- EXP-002: 7.5프레임마다 1개 샘플링
→ 더 세밀한 분석 가능
```

#### 2. 리스크 분석

**낮은 리스크**:
- ✅ 단일 변경 (명확한 인과관계)
- ✅ 다른 로직 전부 유지
- ✅ 검증된 개선 방법

**잠재적 문제**:
- ⚠️ 추론 시간 증가 (3시간 제한 안에는 여유 있음)
- ⚠️ GPU OOM 가능성 낮음 (배치 단위 처리)

---

## 💡 결론 및 다음 단계

### 실험 요약

**핵심 전략**: 검증된 개선 방법부터 단독 테스트

**변경 사항**: NUM_FRAMES 30 → 40만 변경

**예상 효과**: +2~4% (F1 0.57~0.59)

---

### 다음 실험 계획

#### 시나리오 A: EXP-002 성공 시 (F1 > 0.55)
→ **EXP-003**: TTA 추가 (좌우 반전 앙상블)
```python
- NUM_FRAMES = 40 유지
- Horizontal Flip 추가
- 예상: +1~3% 추가 향상
```

#### 시나리오 B: EXP-002 실패 시 (F1 < 0.55)
→ **EXP-003**: NUM_FRAMES 원복 후 TTA 단독 테스트
```python
- NUM_FRAMES = 30 복구
- TTA만 적용
- 프레임 수 vs TTA 효과 비교
```

---

### 장기 전략

1. **단계별 개선**
   - 한 번에 하나씩
   - 효과 명확히 측정
   - 성공한 것만 누적

2. **검증된 기법 우선**
   - ✅ 프레임 수 증가 (EXP-002)
   - ✅ TTA (EXP-003)
   - ✅ 앙상블 (나중에)

3. **위험한 시도는 나중에**
   - ⚠️ 중앙 크롭 (실패 확인)
   - ⚠️ Mean+Max (실패 확인)
   - ⚠️ 프레임 필터링 (실패 확인)

---

## 📝 메모

### 실험 중 관찰 사항
- (결과 나온 후 업데이트)

### 추가 시도할 방법
- TTA (Test Time Augmentation)
- 프레임 샘플링 전략 변경 (시작/중간/끝 집중)
- Margin 조정 (1.3 → 1.4)
- 앙상블 (여러 체크포인트)

### 참고 사항
- 추론 시간 제한: 3시간
- 하루 제출 제한: 3회
- 최소 제출 간격: 30분

