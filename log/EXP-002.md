# EXP-002: 프레임 수 증가 (30→40)

## 📋 실험 정보

| 항목 | 내용 |
|------|------|
| **실험 번호** | EXP-002 |
| **실험 날짜** | 2025-10-29 |
| **베이스 코드** | 베이스라인 (EXP-000) |
| **주요 변경** | NUM_FRAMES: 30 → 40 |
| **F1 Score** | **0.5506** |
| **베이스라인 대비** | **+0.0017 (+0.31%)** |
| **추론 시간** | (서버 추론) |

---

## 🎯 실험 목적

**베이스라인에서 프레임 수만 증가시켜 성능 향상 검증**

- EXP-001에서 여러 변경사항이 오히려 성능 하락 초래
- 가장 안전하고 효과적인 개선 방법부터 단독 테스트
- 더 많은 프레임 = 더 많은 정보 = 더 정확한 판단

---

## 🔧 모델 아키텍처

### 사용 모델
- **백본**: `google/vit-base-patch16-224-in21k`
- **모델**: `deep-fake-detector-v2-model` (베이스라인과 동일)
- **입력 크기**: 224x224
- **출력**: Binary Classification (Real:0, Fake:1)

### 모델 파라미터
```python
model = ViTForImageClassification.from_pretrained(model_path).to("cuda")
processor = ViTImageProcessor.from_pretrained(model_path)
model.eval()
```

---

## 🔄 파이프라인 상세

### 1️⃣ 전처리 (Pre-processing)

#### 얼굴 검출 및 크롭
```python
def detect_and_crop_face_optimized(image, target_size=(224, 224)):
    - dlib face detector 사용
    - margin = 1.3 (베이스라인과 동일)
    - 얼굴 없으면 None 반환
```

#### 프레임 샘플링 ⭐ **변경점**
```python
# 베이스라인
num_frames_to_extract = 30

# EXP-002
num_frames_to_extract = 40  # +33% 증가!
```

**변경 근거**:
- 더 많은 프레임 = 더 풍부한 시간적 정보
- 딥페이크 흔적을 놓칠 확률 감소
- 대부분의 딥페이크 대회에서 효과 검증됨

#### 이미지/비디오 처리
```python
- 이미지: 단일 얼굴 검출
- 비디오: 균등 샘플링 (linspace)
  * 30프레임짜리 → 40프레임 샘플링
  * 시작부터 끝까지 균등 분포
```

#### 전처리 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| `NUM_FRAMES` | 40 | 30 → 40 ⬆️ |
| `margin` | 1.3 | 동일 |
| `target_size` | 224×224 | 동일 |
| `resize_for_detection` | 640 | 동일 |
| `얼굴 미검출 처리` | 레이블 0 | 동일 |

**예상 효과**: +2~4% (더 많은 정보)

---

### 2️⃣ 모델링 (Modeling)

#### 추론 로직
```python
# 배치 단위 GPU 추론 (베이스라인과 동일)
inputs = processor(images=face_images, return_tensors="pt").to("cuda")
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    probs = F.softmax(logits, dim=1)
```

#### 모델 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| 모델 | ViT-Base | 동일 |
| Batch Processing | 사용 | 동일 |
| GPU | CUDA 11.8 | 동일 |

**변경 사항**: 없음 (베이스라인과 동일)

**예상 효과**: 0% (변경 없음)

---

### 3️⃣ 후처리 (Post-processing)

#### 예측 집계 (Aggregation)
```python
# Mean only (베이스라인과 동일)
avg_probs = probs.mean(dim=0)
predicted_class = torch.argmax(avg_probs).item()
```

#### 얼굴 미검출 처리
```python
if not face_images:
    results_to_write[filename] = 0  # Real로 분류 (베이스라인과 동일)
```

#### 후처리 파라미터
| 파라미터 | 값 | 베이스라인 대비 |
|---------|-----|----------------|
| 집계 방법 | Mean only | 동일 |
| 프레임 필터링 | 없음 | 동일 |
| 얼굴 미검출 | 레이블 0 | 동일 |

**변경 사항**: 없음 (베이스라인과 동일)

**예상 효과**: 0% (변경 없음)

---

## 🔄 베이스라인 대비 변경 사항

### 변경 요약

| 단계 | 변경 항목 | 베이스라인 | EXP-002 | 영향 |
|------|----------|-----------|---------|------|
| 전처리 | NUM_FRAMES | 30 | 40 | ⬆️ |
| 모델링 | - | - | - | - |
| 후처리 | - | - | - | - |

### 변경점 상세 분석

#### ✅ 유일한 변경: 프레임 수 증가
```python
num_frames_to_extract = 40  # 30 → 40
```

**장점**:
- ✅ 더 많은 시간적 정보 확보
- ✅ 딥페이크 흔적 포착 확률 증가
- ✅ 검증된 개선 방법
- ✅ 리스크 낮음

**단점**:
- ⚠️ 추론 시간 증가 (70분 → 85~90분)
- ⚠️ GPU 메모리 사용량 소폭 증가

#### ✅ 유지된 것들 (EXP-001 실패 교훈)
```python
✓ 얼굴 없으면 레이블 0 (중앙 크롭 NO!)
✓ Mean only (Mean+Max NO!)
✓ 모든 프레임 사용 (필터링 NO!)
✓ margin = 1.3 (유지)
```

---

## 📊 결과

### 정량적 결과

| 메트릭 | 베이스라인 | EXP-002 | 변화 |
|--------|-----------|---------|------|
| **Macro F1** | 0.5489 | **0.5506** | **+0.0017 (+0.31%)** |
| **정확도 추정** | - | - | - |
| **추론 시간** | ~70분 | (서버 추론) | - |

### 정성적 분석

**실제 결과**: ⚠️ **예상보다 훨씬 낮은 향상**

**예상 vs 실제**:
- 예상: F1 0.57~0.59 (+4~8%)
- 실제: F1 0.5506 (+0.31%)
- 차이: **예상보다 -3.7~7.7% 낮음**

**평가**:
1. ⚠️ **프레임 수 증가 효과 미미**: 통계적 오차 수준
2. ⚠️ **30프레임으로 충분**: 추가 프레임이 중복 정보
3. ⚠️ **추론 시간만 증가**: 성능 향상 없이 비효율적

---

## 🔍 상세 분석

### 성능 영향 요인 분석

#### 1. 프레임 수 증가의 효과

**가설**:
```
더 많은 프레임 → 더 많은 정보 → 더 정확한 판단
```

**메커니즘**:
- 30프레임: 비디오를 30개 구간으로 샘플링
- 40프레임: 비디오를 40개 구간으로 샘플링 (+33%)
- 더 촘촘한 시간 샘플링 → 딥페이크 흔적 놓칠 확률 ⬇️

**예상 시나리오**:
```
비디오 길이가 300프레임이라면:
- 베이스라인: 10프레임마다 1개 샘플링
- EXP-002: 7.5프레임마다 1개 샘플링
→ 더 세밀한 분석 가능
```

#### 2. 리스크 분석

**낮은 리스크**:
- ✅ 단일 변경 (명확한 인과관계)
- ✅ 다른 로직 전부 유지
- ✅ 검증된 개선 방법

**잠재적 문제**:
- ⚠️ 추론 시간 증가 (3시간 제한 안에는 여유 있음)
- ⚠️ GPU OOM 가능성 낮음 (배치 단위 처리)

---

## 💡 결론 및 다음 단계

### 실험 요약

**핵심 전략**: 검증된 개선 방법부터 단독 테스트

**변경 사항**: NUM_FRAMES 30 → 40만 변경

**실제 효과**: +0.31% (F1 0.5506) ⚠️ **예상보다 훨씬 낮음**

**교훈**: 
- 프레임 수 증가만으로는 성능 향상 한계
- 30프레임으로 이미 충분한 정보 확보
- 모델 자체 개선 필요 (파인튜닝, TTA 등)

---

### 다음 실험 계획

#### ✅ 선택된 시나리오: 미미한 향상 (F1 0.5506, +0.31%)

→ **EXP-003 Option A**: 프레임 40 + TTA (현재 코드)
```python
- NUM_FRAMES = 40 유지
- TTA 추가 (좌우 반전)
- 프레임 40 + TTA 조합 효과 검증
- 예상: F1 0.56~0.58 (+1~2%)

장점: 이미 준비됨, TTA 효과 단독 검증 가능
단점: 추론 시간 증가 (140~160분)
```

→ **EXP-003 Option B**: 프레임 30 + TTA (코드 수정)
```python
- NUM_FRAMES = 30 복구
- TTA만 적용
- 프레임 수 효과 배제, TTA만 집중
- 예상: F1 0.56~0.57 (+1~2%)

장점: 추론 시간 절약 (70~90분), TTA 순수 효과
단점: 코드 수정 필요
```

→ **EXP-004**: 바로 파인튜닝
```python
- 단순 기법 한계 확인
- 모델 자체 개선 필요
- FaceForensics++ 파인튜닝
- 예상: F1 0.60~0.65 (+5~10%)

장점: 근본적 성능 향상
단점: 시간 소요 (3~5일)
```

---

### 장기 전략

1. **단계별 개선**
   - 한 번에 하나씩
   - 효과 명확히 측정
   - 성공한 것만 누적

2. **검증된 기법 우선**
   - ✅ 프레임 수 증가 (EXP-002)
   - ✅ TTA (EXP-003)
   - ✅ 앙상블 (나중에)

3. **위험한 시도는 나중에**
   - ⚠️ 중앙 크롭 (실패 확인)
   - ⚠️ Mean+Max (실패 확인)
   - ⚠️ 프레임 필터링 (실패 확인)

---

## 📝 메모

### 실험 중 관찰 사항
- (결과 나온 후 업데이트)

### 추가 시도할 방법
- TTA (Test Time Augmentation)
- 프레임 샘플링 전략 변경 (시작/중간/끝 집중)
- Margin 조정 (1.3 → 1.4)
- 앙상블 (여러 체크포인트)

### 참고 사항
- 추론 시간 제한: 3시간
- 하루 제출 제한: 3회
- 최소 제출 간격: 30분

