# EXP-004: FaceForensics++ 파인튜닝

## 📋 실험 개요
- **실험 번호**: EXP-004
- **실험 일시**: 2025-10-29
- **모델명**: EXP-004-FF++-Finetuned
- **전략**: FaceForensics++ 데이터로 ViT 모델 파인튜닝
- **베이스라인 점수**: 0.5489
- **환경**: Google Colab (L4 GPU)

---

## 🎯 실험 목표

### 주요 목표
1. **공개 데이터셋으로 모델 파인튜닝**
2. **딥페이크 탐지 성능 대폭 향상**
3. **단일 모델로 최고 성능 달성** (앙상블 금지 규칙 준수)

### 가설
- FaceForensics++ 데이터로 파인튜닝하면 베이스라인 대비 10~20% 성능 향상 기대

---

## 📊 데이터셋

### FaceForensics++ (c40)
- **Original**: 100개 비디오
- **DeepFakes**: 100개 비디오
- **총 프레임**: 얼굴 추출 후 수천 개

### 전처리
- **프레임 샘플링**: 비디오당 30 프레임
- **얼굴 탐지**: Dlib frontal face detector
- **크롭**: Bounding box + 40% margin
- **리사이즈**: 224×224 (ViT 입력)

### Train/Val 분할
- **Train**: 80%
- **Val**: 20%
- **Stratified split**: 클래스 균형 유지

---

## 🧠 모델 아키텍처

### 베이스 모델
```python
# Option 1: 베이스라인 모델 (Drive 업로드 시)
MODEL_PATH = "/content/drive/MyDrive/deepfake_models/deep-fake-detector-v2-model"

# Option 2: 원본 ViT 모델 (자동 fallback)
MODEL_PATH = "google/vit-base-patch16-224-in21k"
```

### 모델 구조
- **아키텍처**: ViT-Base-Patch16-224
- **파라미터**: ~86M
- **Pre-trained**: ImageNet-21k
- **Output**: Binary classification (Real: 0, Fake: 1)

---

## 🔧 학습 설정

### 하이퍼파라미터
```python
num_train_epochs = 3
per_device_train_batch_size = 16
per_device_eval_batch_size = 32
learning_rate = 2e-5          # 낮은 LR (파인튜닝)
weight_decay = 0.01
warmup_ratio = 0.1
fp16 = True                   # Mixed precision
```

### 최적화 설정
- **Optimizer**: AdamW (Hugging Face Trainer 기본)
- **Learning Rate Scheduler**: Linear with warmup
- **Warmup**: 전체 step의 10%
- **Mixed Precision**: FP16 (속도/메모리 최적화)

### Evaluation 전략
- **Strategy**: Steps (200 step마다 평가)
- **Metric**: Macro F1-score
- **Best Model**: F1 기준 최고 모델 자동 저장
- **Early Stopping**: 없음 (3 epoch만 학습)

---

## 📈 학습 결과

### Training Progress
| Step | Training Loss | Validation Loss | Val F1 Macro | Val F1 Fake |
|------|--------------|----------------|--------------|-------------|
| 200  | 0.1988       | 0.1426         | **0.9566**   | 0.9569      |
| 400  | 0.0722       | 0.0485         | **0.9867**   | 0.9867      |
| 600  | 0.0310       | 0.0339         | **0.9925**   | 0.9925      |
| 800  | 0.0122       | 0.0313         | **0.9933**   | 0.9933      |

### 최종 성능 (Validation)
```
Validation F1 Macro:  0.9933 (99.33%)
Validation F1 Fake:   0.9933 (99.33%)
Validation Loss:      0.0313
```

### 학습 특징
✅ **안정적인 학습**
- Training loss 지속 감소: 0.1988 → 0.0122
- Validation loss 안정적: 0.1426 → 0.0313
- **과적합 없음!** (train/val loss 함께 감소)

✅ **빠른 수렴**
- Step 200에서 이미 95.66% F1
- Step 400에서 98.67% F1
- Step 800에서 99.33% F1 (거의 완벽)

---

## 🎯 성능 분석

### FaceForensics++ Validation 성능
```
F1 Macro:  0.9933
F1 Fake:   0.9933
Precision: ~0.99
Recall:    ~0.99
```

**해석:**
- FF++ 데이터에서 거의 완벽한 성능
- Real/Fake 구분 매우 정확
- 클래스 불균형 없음 (Macro F1 = Binary F1)

### 베이스라인 대비 개선
| 항목 | 베이스라인 | EXP-004 (Val) | 개선 |
|------|-----------|---------------|------|
| F1 Score | 0.5489 | 0.9933 | **+81.0%** |

**하지만!** ⚠️
- Val 성능은 FF++ 데이터 기준
- 대회 테스트셋은 다른 분포일 가능성
- 실제 성능은 더 낮을 수 있음

---

## 💭 예상 실제 성능

### 낙관적 시나리오 (대회 데이터 ≈ FF++)
```
예상 F1: 0.85~0.95
개선: +55~73%
```

### 현실적 시나리오 (대회 데이터 ≠ FF++)
```
예상 F1: 0.65~0.75
개선: +18~37%
```

### 보수적 시나리오 (대회 데이터 << FF++)
```
예상 F1: 0.58~0.65
개선: +6~18%
```

### 예상 이유
**긍정적 요인:**
- FF++는 다양한 기법 포함 (DeepFakes, Face2Face 등)
- 고품질 학습으로 일반화 능력 향상
- 과적합 없음

**부정적 요인:**
- 대회 데이터는 최신 기법 포함 가능
- 다른 화질/압축률
- 다른 인종/연령 분포

**현실적 예상: F1 0.65~0.70 (+19~28%)** 🎯

---

## 🔬 전처리 (Pre-processing)

### 동일한 전처리 유지
- **프레임 수**: 40 (EXP-002/003과 동일)
- **얼굴 탐지**: Dlib
- **크롭 방식**: Bounding box + margin
- **리사이즈**: 224×224

**변화 없음** - 모델만 교체

---

## 🧠 모델링 (Modeling) ⭐ 핵심 변경

### Before (베이스라인)
```python
model = load("deep-fake-detector-v2-model")
# 원저자가 파인튜닝한 모델
```

### After (EXP-004)
```python
model = load("google/vit-base-patch16-224-in21k")
model = finetune(model, FaceForensics_data, epochs=3)
# FF++ 데이터로 직접 파인튜닝
```

### 파인튜닝 전략
- **Transfer Learning**: ImageNet pre-trained weights 사용
- **Low Learning Rate**: 2e-5 (기존 지식 유지)
- **Short Training**: 3 epochs (과적합 방지)
- **Data Augmentation**: 기본 (Processor 자동)

---

## 📊 후처리 (Post-processing)

### 동일한 집계 방식
```python
# 프레임별 예측 평균
probs = model(frames)  # (40, 2)
avg_prob = probs.mean(dim=0)  # (2,)
pred = argmax(avg_prob)
```

**변화 없음** - EXP-002/003과 동일

---

## 🎯 개선 포인트 요약

### 1. 전처리 (Pre-processing)
- **변화 없음**: EXP-002와 동일

### 2. 모델링 (Modeling) ⭐⭐⭐
- **파인튜닝**: FaceForensics++ 100+100 비디오
- **Learning Rate**: 2e-5 (최적)
- **Epochs**: 3 (과적합 방지)
- **Val F1**: 0.9933 (FF++ 기준)

### 3. 후처리 (Post-processing)
- **변화 없음**: Mean aggregation

---

## 💻 환경 및 소요 시간

### Google Colab 환경
- **GPU**: L4 (24GB VRAM)
- **CPU**: 8 cores
- **RAM**: 48GB

### 소요 시간
- **얼굴 추출 전처리**: ~1-2시간 (비디오 200개)
- **파인튜닝**: ~2-3시간 (3 epochs)
- **총 소요**: ~3-5시간

### 리소스 사용
- **GPU 메모리**: ~10-12GB (배치 16)
- **디스크**: ~5GB (전처리 데이터)
- **효율**: 매우 안정적 (OOM 없음)

---

## 📦 제출 준비

### 1. 모델 저장 위치
```
Colab: /content/deepfake_finetune/output/final_model/
Drive: /content/drive/MyDrive/deepfake_models/faceforensics_finetuned/
ZIP:   /content/drive/MyDrive/deepfake_models/faceforensics_model.zip
```

### 2. 로컬 배치
```bash
# 다운로드 후
압축 해제 → submit/models/faceforensics_finetuned/
```

### 3. task.ipynb 수정
```python
# Cell 15 - 모델 경로 변경
model_path = "./model/faceforensics_finetuned"

# Cell 19 - 제출 정보
aif.submit(
    model_name="EXP-004-FF++-Finetuned",
    key="492f7ace-67d6-4636-8448-25def840e236"  # CUDA 12.6
)
```

### 4. 제출 타이밍
- **EXP-003-Fixed 결과 확인 후** 제출
- 남은 제출 횟수: 0~1회
- 신중하게 결정

---

## 🔄 비교: 베이스라인 vs EXP-004

### 베이스라인 모델
```
원저자 파인튜닝 데이터: 140,002개 이미지
학습 환경: 알 수 없음
Val F1: 0.92 (원저자 보고)
대회 F1: 0.5489
```

### EXP-004 모델
```
파인튜닝 데이터: FF++ 200개 비디오 → 수천 개 프레임
학습 환경: Colab L4 GPU, 3 epochs
Val F1: 0.9933 (FF++ 기준)
대회 F1: 대기 중 (예상 0.65~0.70)
```

### 차이점
1. **데이터**: 베이스라인은 이미지, EXP-004는 FF++ 비디오
2. **학습 방법**: 베이스라인은 from scratch?, EXP-004는 transfer learning
3. **일반화**: 베이스라인은 대회 데이터와 분포 차이, EXP-004도 마찬가지

---

## 💡 인사이트

### 성공 요인
1. **적절한 데이터**: FF++는 고품질 딥페이크 데이터
2. **Transfer Learning**: ImageNet 지식 활용
3. **과적합 방지**: 3 epochs, 낮은 LR
4. **안정적 학습**: Mixed precision, 적절한 배치 크기

### 위험 요소
1. **Domain Shift**: FF++ ≠ 대회 데이터
2. **데이터 양**: 200개 비디오는 적을 수 있음
3. **최신 기법**: 대회 데이터가 FF++보다 최신일 가능성

### 개선 방향
1. **더 많은 데이터**: FF++ 전체 다운로드
2. **다양한 데이터셋**: Celeb-DF, DFDC 추가
3. **더 긴 학습**: 5~10 epochs
4. **Data Augmentation**: 더 강력한 증강

---

## 🎯 다음 단계

### Option A: 즉시 제출 ⭐ (추천)
- EXP-003-Fixed 결과 확인 후
- Val F1 0.99는 충분히 높음
- 실제 성능 확인 필요

### Option B: 더 개선
- FF++ 전체 데이터 다운로드
- Celeb-DF 추가 학습
- 10 epochs 학습

### Option C: 다른 접근
- 다른 아키텍처 시도
- 앙상블... 아니 규칙 위반! ❌

---

## 📊 예상 결과 시나리오

### 시나리오 1: 대성공 (F1 > 0.70)
```
→ 축하! FF++ 파인튜닝 효과 입증
→ 추가 데이터로 더 개선
→ 최종 순위 상위권 기대
```

### 시나리오 2: 성공 (F1 0.60~0.70)
```
→ 의미 있는 개선 (+10~28%)
→ 추가 파인튜닝 고려
→ TTA + 파인튜닝 조합
```

### 시나리오 3: 보통 (F1 0.55~0.60)
```
→ 소폭 개선 (+1~10%)
→ 데이터 문제 가능성
→ 다른 데이터셋 시도
```

### 시나리오 4: 실패 (F1 < 0.55)
```
→ Domain shift 심각
→ 베이스라인으로 복귀
→ 다른 전략 필요
```

---

## 📌 핵심 요약

### 실험 결과
- **Val F1**: 0.9933 (FF++ 기준)
- **학습 안정성**: 매우 안정적
- **과적합**: 없음
- **소요 시간**: 3-5시간

### 기대 효과
- **예상 F1**: 0.65~0.70
- **예상 개선**: +19~28%
- **불확실성**: Domain shift 영향

### 제출 전략
- EXP-003-Fixed 결과 확인 후
- 신중하게 제출
- 남은 제출 횟수 고려

---

## 🔖 태그

`#FaceForensics++` `#FineTuning` `#TransferLearning` `#ViT` `#99%Accuracy` `#Colab` `#L4GPU`

---

## 📊 결과 (업데이트 예정)

**제출 대기 중...**

- **제출 시간**: TBD
- **실제 F1**: TBD
- **베이스라인 대비**: TBD
- **순위**: TBD

---

**마지막 업데이트**: 2025-10-29  
**상태**: 파인튜닝 완료, 제출 준비 중  
**다음**: EXP-003-Fixed 결과 확인 → EXP-004 제출 결정

