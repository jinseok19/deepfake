# EXP-005: 라벨 반전 실험

## 📋 실험 개요
- **실험 번호**: EXP-005
- **실험 일시**: 2025-10-30
- **모델명**: EXP-005-FF++-Finetuned-TTA-LabelFlip
- **전략**: EXP-004 + 라벨 반전 (0↔1)
- **베이스라인 점수**: 0.5489
- **EXP-004 점수**: 0.2773 (실패)

---

## 🎯 실험 목적

### EXP-004 실패 원인 분석
1. **모델 경로 불일치**: `wilddeepfake_finetuned` → `deepfake-finetuned` ✅ 수정됨
2. **라벨 반전 가능성**: 0.2773 → 1-x = 0.7227?

### 실험 가설
**만약 라벨이 반대로 학습되었다면:**
- Real(0)과 Fake(1)이 반대로 예측됨
- 라벨 반전 시 0.7227 기대 (베이스라인 대비 +31.7%)

---

## 🔧 수정 사항

### Before (EXP-004)
```python
# 3. TTA 앙상블 (원본 + 반전 평균)
avg_probs = (probs_orig + probs_flip) / 2.0
predicted_class = torch.argmax(avg_probs).item()
results_to_write[filename] = predicted_class
```

### After (EXP-005)
```python
# 3. TTA 앙상블 (원본 + 반전 평균)
avg_probs = (probs_orig + probs_flip) / 2.0
predicted_class = torch.argmax(avg_probs).item()

# EXP-005: 라벨 반전 (0→1, 1→0)
predicted_class = 1 - predicted_class

results_to_write[filename] = predicted_class
```

**변경점: 예측 라벨을 반전 (0→1, 1→0)**

---

## 📊 예상 결과 시나리오

### 시나리오 1: 라벨 반전이 정답 (기대)
```
EXP-004: 0.2773
EXP-005: 0.7227 (1 - 0.2773)
개선: +163.4% 🚀
베이스라인 대비: +31.7%
```

**→ 대박 성과!**

### 시나리오 2: 모델 로딩 문제 (현실적)
```
EXP-004: 0.2773 (모델 로딩 실패)
EXP-005: ~0.65-0.75 (정상 작동)
개선: 모델 경로 수정 효과
```

**→ 라벨 반전보다 모델 경로 수정이 주효**

### 시나리오 3: 여전히 실패
```
EXP-005: 0.2773 근처
→ 다른 문제 존재
→ 추가 디버깅 필요
```

---

## 🔬 파이프라인

### 1️⃣ 전처리 (Pre-processing)
- **동일**: EXP-004와 동일
- 프레임 수: 40
- 얼굴 탐지: Dlib
- 리사이즈: 224×224

### 2️⃣ 모델링 (Modeling)
- **동일**: EXP-004와 동일
- 모델: `./model/deepfake-finetuned`
- TTA: 원본 + 좌우 반전

### 3️⃣ 후처리 (Post-processing)
- **변경**: 라벨 반전 추가 ⭐
- `predicted_class = 1 - predicted_class`

---

## 💡 인사이트

### 라벨 반전이 필요한 경우
1. **학습 시 라벨 정의 불일치**
   - 모델: Real=1, Fake=0
   - 대회: Real=0, Fake=1
   
2. **데이터 로드 시 라벨 반전**
   - FaceForensics++ 라벨링 방식
   - 대회 라벨링 방식 불일치

3. **Config 파일 확인 결과**
```json
"id2label": {
  "0": "Realism",
  "1": "Deepfake"
}
```
**→ 라벨은 정상! (0=Real, 1=Fake)**

### 그럼 왜 0.2773?
1. **모델 경로 불일치** (가능성 높음)
   - `wilddeepfake_finetuned` ≠ `deepfake-finetuned`
   - 모델 로딩 실패 → 랜덤/기본 모델

2. **Domain Shift** (가능성 중간)
   - FF++ 데이터 ≠ 대회 데이터
   - 하지만 Val 99% → 실제 27%는 너무 극단적

3. **라벨 반전** (가능성 낮음)
   - Config는 정상
   - 하지만 실제 학습 시 반전됐을 가능성

---

## 🎯 다음 단계

### EXP-005 제출 후
1. **F1 > 0.65**: 모델 경로 수정이 주효 ✅
2. **F1 ~ 0.72**: 라벨 반전도 효과 있음 ✅✅
3. **F1 ~ 0.27**: 다른 문제 존재 ❌

### 추가 실험 계획
- **EXP-006**: 더 많은 데이터로 파인튜닝
- **EXP-007**: 다른 아키텍처 시도
- **EXP-008**: 앙상블... 아니 규칙 위반! ❌

---

## 📌 핵심 요약

### 변경 사항
- ✅ 모델 경로 수정 완료
- ✅ 라벨 반전 로직 추가
- ✅ 제출 이름 변경

### 기대 효과
- **최선**: F1 0.72 (라벨 반전 정답)
- **현실**: F1 0.65-0.70 (모델 경로 수정)
- **최악**: F1 0.27 (다른 문제)

### 제출 정보
- **모델명**: EXP-005-FF++-Finetuned-TTA-LabelFlip
- **CUDA**: 12.6
- **Key**: 492f7ace-67d6-4636-8448-25def840e236

---

## 📊 결과

### 제출 이력

#### v1 (2025.10.30 05:03:44)
- **상태**: ❌ 실패
- **오류**: "점수를 산출할 수 없었습니다"
- **원인**: 라벨 반전 로직이 추론 중에 적용되어 예외 발생 가능성
- **조치**: CSV 작성 시 일괄 반전으로 수정

#### v2 (2025.10.30 13:45:15)
- **상태**: ❌ 대실패
- **제출 시간**: 2025.10.30 13:45
- **실제 F1**: **0.4082**
- **베이스라인 대비**: **-25.6%** ❌
- **원인**: 라벨 반전이 역효과 (모델은 정상)

---

## 🔧 v2 수정 사항

### 변경된 로직
```python
# v1 (실패)
predicted_class = torch.argmax(avg_probs).item()
predicted_class = 1 - predicted_class  # 추론 중 반전
results_to_write[filename] = predicted_class

# v2 (수정)
predicted_class = torch.argmax(avg_probs).item()
results_to_write[filename] = predicted_class  # 그대로 저장

# CSV 작성 시 일괄 반전
label = results_to_write.get(filename, 0)
label = 1 - label  # 마지막에 반전!
writer.writerow([filename, label])
```

---

---

## 📊 최종 결과 분석

### 실험 결과
- **EXP-004 (FF++ Finetune)**: 0.2773
- **EXP-005 (라벨 반전)**: 0.4082
- **차이**: +0.1309 (개선되었지만 여전히 실패)

### 결론
1. ✅ **라벨 반전이 부분적 개선**: 0.2773 → 0.4082 (+47%)
2. ❌ **모델 자체가 대회 데이터에 맞지 않음**: 여전히 베이스라인 대비 -25.6%
3. ❌ **FF++ 파인튜닝 전략 실패**: Domain shift가 너무 큼

### 학습한 교훈
- **파인튜닝은 공개 데이터만으로는 부족**
- **대회 데이터와 유사한 데이터 수집이 필수**
- **다음은 직접 데이터 생성 전략으로 전환**

---

**마지막 업데이트**: 2025-10-30  
**상태**: ❌ 실패 (F1 0.4082)  
**다음**: 데이터 수집 + 직접 생성 전략 (EXP-006 이후)

